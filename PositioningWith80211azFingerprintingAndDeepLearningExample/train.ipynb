{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76534fa3-6d11-429d-af28-5978ea704bb2",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "Try adding skip connections, resnet style\n",
    "\n",
    "1. [x] load dataset into tensor, convert to float32  \n",
    "    - [x] apply normalization\n",
    "2. [x] Implement DataParallel training  \n",
    "    - [x] increase minibatch size to 128 for 32 per device\n",
    "3. [ ] try training and benchmark speed\n",
    "4. [ ] fix simulation script to get the correct labels and retrain\n",
    "\n",
    "gpu datasheet (we have sxm version): https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf\n",
    "\n",
    "TODO: change dataparallel to distributed data parallel at some point, and move everything from the notebook into a training script\n",
    "\n",
    "Links:\n",
    "https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ae07a7-9241-40fe-bd45-013bd062aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from torchvision.transforms import Normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e8c29-0212-4228-a63c-cf36ee0813df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a49077-d5dc-49b9-a495-8ebeb8ea5b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04-19_spectrogram_MyCNN-double-conv_mse-euc-hybrid-loss'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_ = '04-19'\n",
    "dataset_name = 'spectrogram'\n",
    "model_type = 'MyCNN-double-conv'\n",
    "# model_type = 'Simple-NN'\n",
    "loss_name = 'mse-euc-hybrid-loss'\n",
    "model_name = '_'.join([date_, dataset_name, model_type, loss_name])\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82343b3f-3318-486b-ad5a-5dfc12dd5e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce34698c-86c9-4488-9894-87f468a79068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-SXM4-80GB\n",
      "NVIDIA A100-SXM4-80GB\n",
      "NVIDIA A100-SXM4-80GB\n",
      "NVIDIA A100-SXM4-80GB\n",
      "NVIDIA DGX Display\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "    \n",
    "# use devices 0-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996643e-08b9-4441-9791-9e29639b0dc7",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597f8402-11a0-47c8-9e97-33cb19abc744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1920, 1, 300, 1024]),\n",
       " torch.Size([1920, 3]),\n",
       " torch.float32,\n",
       " torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spectrogram:\n",
    "\n",
    "feats = h5py.File('samplesChirp.mat', 'r')\n",
    "labels = h5py.File('labelsChirp.mat', 'r')\n",
    "feats_da = da.from_array(feats['samples']).astype('float32') # cast to float32\n",
    "feats_da = feats_da[:,None,:,:] # add channel dimension\n",
    "labels_da = da.from_array(labels['labels']['position']).astype('float32')\n",
    "X = torch.Tensor(feats_da.compute())\n",
    "Y = torch.Tensor(labels_da.compute())\n",
    "\n",
    "X.shape, Y.shape, X.dtype, Y.dtype\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# feats4T:\n",
    "\n",
    "# feats, labels = scipy.io.loadmat('output/feats4T_.1R.mat'), scipy.io.loadmat('output/labels4T_.1R.mat')\n",
    "\n",
    "# feats = feats['features']\n",
    "# feats = feats.astype('float32')\n",
    "# feats = feats.T\n",
    "# feats = feats.reshape((feats.shape[0], -1, feats.shape[-1]))\n",
    "# feats = feats[:, None, :, :]\n",
    "\n",
    "# labels = labels['lp']\n",
    "# labels = labels.astype('float32')\n",
    "# labels = labels.T\n",
    "\n",
    "# X = torch.Tensor(feats)\n",
    "# Y = torch.Tensor(labels)\n",
    "\n",
    "# X.shape, Y.shape, X.dtype, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1e4d4-a8a1-4d69-bde3-3c85148cd1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c52784-f7ed-4a90-b50c-9765b496a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c166c57-66a6-4cf4-b60c-cd8f02182a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.6102), tensor(26.3429))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mean = X_train.mean()\n",
    "X_train_std = X_train.std()\n",
    "X_train_mean, X_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824ac67-f5e8-4c72-9e82-cb260a15c702",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "1. create custom Dataset class based on TensorDataset that will apply a normalization transform if provided\n",
    "2. create train and test datasets, pass in X_train_mean and X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4322f908-18b0-4d67-8fa2-3a419cc8b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, tensors, transforms=None):\n",
    "        # check to make sure number of samples match\n",
    "        assert all(tensors[0].shape[0] == tens.shape[0] for tens in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            x = self.transforms(x)\n",
    "            \n",
    "        y = self.tensors[1][index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.tensors[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c769512-f662-4489-9c87-781921c41fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomTensorDataset([X_train, Y_train], Normalize(X_train_mean, X_train_std))\n",
    "test_dataset = CustomTensorDataset([X_test, Y_test], Normalize(X_train_mean, X_train_std))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65c698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e06d19fa-4f93-4466-9439-b085664b0896",
   "metadata": {},
   "source": [
    "### Define models and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03cf0009-b224-4b40-a244-5803a0cef500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        \n",
    "        linear_in_dim = 303104 # SPECTROGRAM DSET\n",
    "        # linear_in_dim = 768 # FEATS4T DSET\n",
    "        # 1 x 16 x 48 shape of each sample\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            # conv block 1\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            # conv block 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Dropout2d(p=0.2),\n",
    "\n",
    "            # conv block 3\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            # linear block\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linear_in_dim, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "        \n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(768, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "def EucLoss(a: torch.Tensor, b: torch.Tensor, reduction='avg') -> torch.Tensor:\n",
    "    assert a.shape == b.shape\n",
    "    assert b.shape[-1] == 3\n",
    "    \n",
    "    if reduction == 'sum':\n",
    "        return torch.sum((a-b).square(), dim=-1).sqrt().sum()\n",
    "    else:\n",
    "        return torch.sum((a-b).square(), dim=-1).sqrt().mean()\n",
    "\n",
    "def EucLossSquared(a: torch.Tensor, b: torch.Tensor, reduction='avg') -> torch.Tensor:\n",
    "    assert a.shape == b.shape\n",
    "    assert b.shape[-1] == 3\n",
    "    \n",
    "    if reduction == 'sum':\n",
    "        return (a-b).square().sum()\n",
    "    else:\n",
    "        return torch.sum((a-b).square(), dim=-1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "348fcabd-f549-4bd5-8e8e-8a995acec81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MyCNN(\n",
       "    (seq): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU()\n",
       "      (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU()\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU()\n",
       "      (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU()\n",
       "      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (21): Flatten(start_dim=1, end_dim=-1)\n",
       "      (22): Linear(in_features=303104, out_features=1000, bias=True)\n",
       "      (23): ReLU()\n",
       "      (24): Linear(in_features=1000, out_features=100, bias=True)\n",
       "      (25): ReLU()\n",
       "      (26): Linear(in_features=100, out_features=20, bias=True)\n",
       "      (27): ReLU()\n",
       "      (28): Linear(in_features=20, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.DataParallel(MyCNN(), device_ids=[0,1,2,3]).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd1d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45247b73-15e4-44a8-b4e8-e737dff343bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloss = nn.MSELoss()\n",
    "testloss = partial(EucLoss, reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.RMSprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9724b-bdc6-4d05-be1c-3c667b27d6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b855d290-d4e8-4a60-ad2f-c23c10af4117",
   "metadata": {},
   "source": [
    "#### Training/Evaluating NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6d8b7-884d-4d93-be50-8fe96ab82449",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss (MSE) = 57.2544 | Test loss (Euc Dist) = 3.6169\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100 \n",
    "loss_tracker = np.zeros((num_epochs, 2))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0    \n",
    "    model = model.train()\n",
    "    \n",
    "    for batch_idx, (ft, lbl) in enumerate(train_loader):\n",
    "        # ft, lbl = ft.to(device), lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(ft)\n",
    "        lbl = lbl.cuda()\n",
    "        # loss = crit(output, lbl, reduction='sum')\n",
    "        loss = trainloss(output, lbl)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    loss_tracker[epoch, 0] = train_loss\n",
    "        \n",
    "    \n",
    "    test_loss = 0\n",
    "    model = model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (ft, lbl) in enumerate(test_loader):\n",
    "            # ft, lbl = ft.to(device), lbl.to(device)\n",
    "            output = model(ft)\n",
    "            lbl = lbl.cuda()\n",
    "            # loss = crit(output, lbl, reduction='sum')\n",
    "            loss = testloss(output, lbl)\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_dataset) # get average loss per sample of whole dataset\n",
    "    loss_tracker[epoch, 1] = test_loss\n",
    "            \n",
    "    print('Epoch {} | Training loss (MSE) = {:.4f} | Test loss (Euc Dist) = {:.4f}'.format(epoch, train_loss, test_loss))\n",
    "    \n",
    "    \n",
    "# make plot\n",
    "img_dir = Path('./loss_plots')\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.figure()\n",
    "plt.plot(loss_tracker)\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.savefig(img_dir / ('{}.png'.format(model_name)))\n",
    "\n",
    "# export loss_tracker as csv\n",
    "loss_dir = Path('./loss_data')\n",
    "loss_dir.mkdir(parents=True, exist_ok=True)\n",
    "pd.DataFrame(loss_tracker, columns=['Train', 'Test']).to_csv(loss_dir / ('{}.csv'.format(model_name)))\n",
    "\n",
    "# save model\n",
    "model_dir = Path('./models')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), model_dir / ('{}.pt'.format(model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1262ce8",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "CNN seemed to help accuracy, as well as more linear layers. However, it is overfitting heavily. Batchnorm didn't really make a difference, dropout seems to make things worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b856b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe019a-3d55-4504-bad6-0756d45428fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bae306-1d1f-4254-9746-466757b46e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
